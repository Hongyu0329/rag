{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-intro",
   "metadata": {},
   "source": [
    "# NVIDIA RAG Blueprint - Complete Test Pipeline\n",
    "\n",
    "This notebook provides a complete end-to-end test of the NVIDIA RAG Blueprint system with:\n",
    "\n",
    "- ‚úÖ **Unlimited Processing Time**: No timeouts, processes until complete\n",
    "- ‚úÖ **Real-time Progress Monitoring**: Visual progress indicators and status updates  \n",
    "- ‚úÖ **Professional Error Handling**: Comprehensive error detection and recovery\n",
    "- ‚úÖ **Complete Pipeline Testing**: From document upload to query responses\n",
    "\n",
    "## Prerequisites\n",
    "- RAG services running (RAG server on 8081, Ingestor on 8082)\n",
    "- Vector database (Milvus) initialized\n",
    "- NGC API key configured for cloud embedding models\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cell-imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports and async setup complete\n"
     ]
    }
   ],
   "source": [
    "# === IMPORTS AND SETUP ===\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import logging\n",
    "from typing import Dict, Any, Optional, List, Union\n",
    "from pathlib import Path\n",
    "\n",
    "# Async operations setup\n",
    "try:\n",
    "    import aiohttp\n",
    "    import asyncio\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "except ImportError:\n",
    "    print(\"Installing required packages...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call([\"pip\", \"install\", \"-q\", \"aiohttp\", \"nest_asyncio\"])\n",
    "    import aiohttp\n",
    "    import asyncio\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "\n",
    "# Logging setup\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úÖ All imports and async setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cell-config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration loaded\n",
      "   RAG Server: http://localhost:8081\n",
      "   Ingestor: http://localhost:8082\n",
      "   Collection: multimodal_data\n"
     ]
    }
   ],
   "source": [
    "# === CONFIGURATION ===\n",
    "class RAGConfig:\n",
    "    \"\"\"Centralized configuration for RAG system\"\"\"\n",
    "    \n",
    "    # Service endpoints\n",
    "    IPADDRESS = \"localhost\"\n",
    "    RAG_PORT = \"8081\"\n",
    "    INGESTOR_PORT = \"8082\"\n",
    "    \n",
    "    # URLs\n",
    "    RAG_BASE_URL = f\"http://{IPADDRESS}:{RAG_PORT}\"\n",
    "    INGESTOR_BASE_URL = f\"http://{IPADDRESS}:{INGESTOR_PORT}\"\n",
    "    \n",
    "    # API endpoints  \n",
    "    RAG_HEALTH_URL = f\"{RAG_BASE_URL}/v1/health\"\n",
    "    CHAIN_URL = f\"{RAG_BASE_URL}/v1/generate\"\n",
    "    SEARCH_URL = f\"{RAG_BASE_URL}/v1/search\"\n",
    "    \n",
    "    INGESTOR_HEALTH_URL = f\"{INGESTOR_BASE_URL}/v1/health\"\n",
    "    DOCUMENTS_URL = f\"{INGESTOR_BASE_URL}/v1/documents\"\n",
    "    COLLECTION_URL = f\"{INGESTOR_BASE_URL}/v1/collection\"\n",
    "    COLLECTIONS_URL = f\"{INGESTOR_BASE_URL}/v1/collections\"\n",
    "    \n",
    "    # Collection settings\n",
    "    COLLECTION_NAME = \"multimodal_data\"\n",
    "    EMBEDDING_DIMENSION = 2048  # NVIDIA embedding model dimension\n",
    "    \n",
    "    # Headers\n",
    "    HEADERS = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Accept\": \"application/json\"\n",
    "    }\n",
    "\n",
    "config = RAGConfig()\n",
    "print(\"‚úÖ Configuration loaded\")\n",
    "print(f\"   RAG Server: {config.RAG_BASE_URL}\")\n",
    "print(f\"   Ingestor: {config.INGESTOR_BASE_URL}\")\n",
    "print(f\"   Collection: {config.COLLECTION_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cell-health-functions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Health check functions defined\n"
     ]
    }
   ],
   "source": [
    "# === HEALTH CHECK FUNCTIONS ===\n",
    "\n",
    "async def check_service_health(service_name: str, url: str, timeout: int = 10) -> Dict[str, Any]:\n",
    "    \"\"\"Check health of a specific service\"\"\"\n",
    "    try:\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(url, timeout=aiohttp.ClientTimeout(total=timeout)) as response:\n",
    "                if response.status == 200:\n",
    "                    result = await response.json()\n",
    "                    return {\"healthy\": True, \"status\": response.status, \"details\": result}\n",
    "                else:\n",
    "                    return {\"healthy\": False, \"status\": response.status, \"error\": \"Non-200 status\"}\n",
    "    except asyncio.TimeoutError:\n",
    "        return {\"healthy\": False, \"error\": \"Timeout\"}\n",
    "    except Exception as e:\n",
    "        return {\"healthy\": False, \"error\": str(e)}\n",
    "\n",
    "async def comprehensive_health_check() -> Dict[str, Any]:\n",
    "    \"\"\"Perform complete health check on all services\"\"\"\n",
    "    print(\"üîç Starting comprehensive health check...\")\n",
    "    \n",
    "    # Check services\n",
    "    services = {\n",
    "        \"RAG Server\": config.RAG_HEALTH_URL,\n",
    "        \"Ingestor Service\": config.INGESTOR_HEALTH_URL\n",
    "    }\n",
    "    \n",
    "    health_results = {}\n",
    "    for service_name, url in services.items():\n",
    "        health_results[service_name] = await check_service_health(service_name, url)\n",
    "    \n",
    "    # Check vector database\n",
    "    try:\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(config.COLLECTIONS_URL, timeout=aiohttp.ClientTimeout(total=10)) as response:\n",
    "                if response.status == 200:\n",
    "                    collections = await response.json()\n",
    "                    collection_names = [c.get('collection_name', 'unknown') for c in collections.get('collections', [])]\n",
    "                    health_results[\"Vector Database\"] = {\n",
    "                        \"healthy\": True,\n",
    "                        \"collections\": collection_names,\n",
    "                        \"target_collection_exists\": config.COLLECTION_NAME in collection_names\n",
    "                    }\n",
    "                else:\n",
    "                    health_results[\"Vector Database\"] = {\"healthy\": False, \"error\": f\"Status {response.status}\"}\n",
    "    except Exception as e:\n",
    "        health_results[\"Vector Database\"] = {\"healthy\": False, \"error\": str(e)}\n",
    "    \n",
    "    # Calculate summary\n",
    "    all_healthy = all(result.get(\"healthy\", False) for result in health_results.values())\n",
    "    target_collection_exists = health_results.get(\"Vector Database\", {}).get(\"target_collection_exists\", False)\n",
    "    \n",
    "    return {\n",
    "        \"overall_healthy\": all_healthy,\n",
    "        \"target_collection_exists\": target_collection_exists,\n",
    "        \"services\": health_results\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Health check functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cell-health-check",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Starting comprehensive health check...\n",
      "\n",
      "============================================================\n",
      "üè• HEALTH CHECK RESULTS\n",
      "============================================================\n",
      "‚úÖ RAG Server: Healthy\n",
      "‚úÖ Ingestor Service: Healthy\n",
      "‚úÖ Vector Database: Healthy\n",
      "   Collections: ['multimodal_data', 'metadata_schema', 'test_collection', 'meta']\n",
      "\n",
      "üìä Overall Status: ‚úÖ All Systems Operational\n",
      "üìÅ Target Collection: ‚úÖ Exists\n",
      "\n",
      "‚úÖ All services ready - proceeding to next steps\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# === RUN HEALTH CHECK ===\n",
    "\n",
    "health_status = await comprehensive_health_check()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üè• HEALTH CHECK RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for service, status in health_status[\"services\"].items():\n",
    "    emoji = \"‚úÖ\" if status.get(\"healthy\") else \"‚ùå\"\n",
    "    print(f\"{emoji} {service}: {'Healthy' if status.get('healthy') else 'Unhealthy'}\")\n",
    "    if status.get(\"error\"):\n",
    "        print(f\"   Error: {status['error']}\")\n",
    "    if service == \"Vector Database\" and status.get(\"collections\"):\n",
    "        print(f\"   Collections: {status['collections']}\")\n",
    "\n",
    "print(f\"\\nüìä Overall Status: {'‚úÖ All Systems Operational' if health_status['overall_healthy'] else '‚ùå Issues Detected'}\")\n",
    "print(f\"üìÅ Target Collection: {'‚úÖ Exists' if health_status['target_collection_exists'] else '‚ö†Ô∏è Missing'}\")\n",
    "\n",
    "if not health_status[\"overall_healthy\"]:\n",
    "    print(\"\\n‚ùå CRITICAL: Services not healthy - cannot proceed\")\n",
    "    print(\"   Please start all required services before continuing\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ All services ready - proceeding to next steps\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cell-collection-functions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Collection and document management functions defined\n"
     ]
    }
   ],
   "source": [
    "# === COLLECTION AND DOCUMENT MANAGEMENT ===\n",
    "\n",
    "async def create_collection_if_needed(collection_name: str = None) -> bool:\n",
    "    \"\"\"Create collection in vector store if it doesn't exist\"\"\"\n",
    "    if collection_name is None:\n",
    "        collection_name = config.COLLECTION_NAME\n",
    "    \n",
    "    data = {\n",
    "        \"collection_name\": collection_name,\n",
    "        \"embedding_dimension\": config.EMBEDDING_DIMENSION\n",
    "    }\n",
    "    \n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        try:\n",
    "            async with session.post(config.COLLECTION_URL, json=data, headers=config.HEADERS) as response:\n",
    "                if response.status == 200:\n",
    "                    print(f\"‚úÖ Collection '{collection_name}' created successfully!\")\n",
    "                    return True\n",
    "                else:\n",
    "                    result = await response.text()\n",
    "                    if \"already exists\" in result.lower():\n",
    "                        print(f\"‚ÑπÔ∏è  Collection '{collection_name}' already exists\")\n",
    "                        return True\n",
    "                    else:\n",
    "                        print(f\"‚ö†Ô∏è Failed to create collection: {result}\")\n",
    "                        return False\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error creating collection: {e}\")\n",
    "            return False\n",
    "\n",
    "async def get_document_count(collection_name: str = None) -> int:\n",
    "    \"\"\"Get current document count in collection\"\"\"\n",
    "    if collection_name is None:\n",
    "        collection_name = config.COLLECTION_NAME\n",
    "    \n",
    "    try:\n",
    "        params = {\"collection_name\": collection_name}\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(config.DOCUMENTS_URL, params=params) as response:\n",
    "                if response.status == 200:\n",
    "                    result = await response.json()\n",
    "                    return result.get('total_documents', 0)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error getting document count: {e}\")\n",
    "    return 0\n",
    "\n",
    "def create_test_document() -> str:\n",
    "    \"\"\"Create a comprehensive test document with facts for RAG testing\"\"\"\n",
    "    \n",
    "    test_document_content = \"\"\"# NVIDIA RAG Test Document\n",
    "\n",
    "## Introduction\n",
    "This is a comprehensive test document for the NVIDIA RAG Blueprint system. It contains various facts and information designed to test the retrieval and generation capabilities.\n",
    "\n",
    "## Test Facts\n",
    "\n",
    "### Geography\n",
    "- The capital of France is Paris, known for the Eiffel Tower and rich cultural heritage\n",
    "- Tokyo is the capital of Japan and one of the world's most populous metropolitan areas\n",
    "- London is the capital of the United Kingdom, located on the River Thames\n",
    "- New York City is the largest city in the United States by population\n",
    "\n",
    "### Technology\n",
    "- Python is a high-level programming language created by Guido van Rossum in 1991\n",
    "- JavaScript is the programming language of the web, enabling interactive websites\n",
    "- Docker containers provide isolated environments for running applications consistently\n",
    "- Kubernetes orchestrates containerized applications across clusters of machines\n",
    "- Git is a distributed version control system for tracking changes in source code\n",
    "\n",
    "### Artificial Intelligence\n",
    "- Machine learning models can process natural language and understand context\n",
    "- The NVIDIA embedding model produces 2048-dimensional vectors for text representation\n",
    "- The RTX 5070 Ti is a powerful GPU designed for AI workloads and gaming\n",
    "- The RTX 4060 is a consumer GPU suitable for moderate AI tasks\n",
    "- RAG stands for Retrieval Augmented Generation, combining search with AI generation\n",
    "- Vector embeddings enable semantic search and similarity matching\n",
    "- Transformer models revolutionized natural language processing since 2017\n",
    "- BERT and GPT are popular transformer-based architectures\n",
    "- Milvus is a vector database optimized for storing and searching embeddings\n",
    "\n",
    "### Computing Concepts\n",
    "- CPU stands for Central Processing Unit, the brain of the computer\n",
    "- GPU stands for Graphics Processing Unit, optimized for parallel processing\n",
    "- RAM provides fast temporary storage for active programs and data\n",
    "- SSD offers faster storage than traditional hard disk drives\n",
    "- VRAM is dedicated memory on graphics cards for visual processing\n",
    "- CUDA enables parallel computing acceleration on NVIDIA GPUs\n",
    "\n",
    "### Cloud Computing\n",
    "- Cloud NIMs provide AI models as a service without local hardware requirements\n",
    "- API endpoints allow remote access to computational resources\n",
    "- Latency is the delay between request and response in network communications\n",
    "- Throughput measures the amount of data processed per unit time\n",
    "\n",
    "## System Architecture\n",
    "The NVIDIA RAG Blueprint uses a microservices architecture with:\n",
    "- Ingestion service for document processing\n",
    "- Embedding service for vector generation\n",
    "- Vector database for similarity search\n",
    "- LLM service for response generation\n",
    "- Reranking service for result optimization\n",
    "\n",
    "## Performance Metrics\n",
    "- Default chunk size: 512 tokens\n",
    "- Chunk overlap: 150 tokens  \n",
    "- Embedding dimensions: 2048\n",
    "- Processing time: varies with cloud API response\n",
    "\n",
    "This document tests the complete RAG pipeline from ingestion to query response.\n",
    "\"\"\"\n",
    "    \n",
    "    # Save test document\n",
    "    test_file_path = \"rag_test_document.md\"\n",
    "    with open(test_file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(test_document_content)\n",
    "    \n",
    "    print(f\"‚úÖ Test document created: {test_file_path}\")\n",
    "    print(f\"   Size: {len(test_document_content):,} characters\")\n",
    "    print(f\"   Location: {os.path.abspath(test_file_path)}\")\n",
    "    \n",
    "    return test_file_path\n",
    "\n",
    "print(\"‚úÖ Collection and document management functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cell-setup-collection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Ensuring collection 'multimodal_data' exists...\n",
      "‚úÖ Collection 'multimodal_data' created successfully!\n",
      "üìä Current documents in collection: 0\n",
      "\n",
      "üìÑ Creating test document...\n",
      "‚úÖ Test document created: rag_test_document.md\n",
      "   Size: 2,977 characters\n",
      "   Location: /home/hongyu/Documents/rag/notebooks/rag_test_document.md\n"
     ]
    }
   ],
   "source": [
    "# === SETUP COLLECTION AND DOCUMENT ===\n",
    "\n",
    "if health_status[\"overall_healthy\"]:\n",
    "    print(f\"üìÅ Ensuring collection '{config.COLLECTION_NAME}' exists...\")\n",
    "    collection_ready = await create_collection_if_needed(config.COLLECTION_NAME)\n",
    "    \n",
    "    if collection_ready:\n",
    "        initial_doc_count = await get_document_count(config.COLLECTION_NAME)\n",
    "        print(f\"üìä Current documents in collection: {initial_doc_count}\")\n",
    "        \n",
    "        # Create test document\n",
    "        print(f\"\\nüìÑ Creating test document...\")\n",
    "        test_file_path = create_test_document()\n",
    "    else:\n",
    "        print(\"‚ùå Failed to create/verify collection\")\n",
    "        collection_ready = False\n",
    "        test_file_path = None\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Skipping setup - services not healthy\")\n",
    "    collection_ready = False\n",
    "    test_file_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cell-upload-functions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Unlimited time upload functions defined\n"
     ]
    }
   ],
   "source": [
    "# === UNLIMITED TIME UPLOAD FUNCTIONS ===\n",
    "\n",
    "async def upload_document_unlimited_time(file_path: str, collection_name: str = None) -> bool:\n",
    "    \"\"\"Upload document with UNLIMITED processing time and progress monitoring\"\"\"\n",
    "    if collection_name is None:\n",
    "        collection_name = config.COLLECTION_NAME\n",
    "    \n",
    "    # Check initial state\n",
    "    initial_count = await get_document_count(collection_name)\n",
    "    print(f\"üìä Initial document count: {initial_count}\")\n",
    "    \n",
    "    # Prepare upload data\n",
    "    data = {\n",
    "        \"collection_name\": collection_name,\n",
    "        \"blocking\": False,  # Use non-blocking for progress monitoring\n",
    "        \"split_options\": {\n",
    "            \"chunk_size\": 512,\n",
    "            \"chunk_overlap\": 150\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Prepare form data\n",
    "    form_data = aiohttp.FormData()\n",
    "    \n",
    "    try:\n",
    "        file_size = os.path.getsize(file_path)\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            form_data.add_field(\n",
    "                \"documents\", \n",
    "                f.read(), \n",
    "                filename=os.path.basename(file_path),\n",
    "                content_type=\"application/octet-stream\"\n",
    "            )\n",
    "        print(f\"üìÑ File: {os.path.basename(file_path)} ({file_size:,} bytes)\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå File not found: {file_path}\")\n",
    "        return False\n",
    "    \n",
    "    form_data.add_field(\"data\", json.dumps(data), content_type=\"application/json\")\n",
    "    \n",
    "    print(f\"üöÄ Starting upload with UNLIMITED processing time...\")\n",
    "    print(f\"   Will monitor progress until completion (no timeout)\")\n",
    "    print(f\"   Press Ctrl+C to interrupt if needed\\n\")\n",
    "    \n",
    "    # Upload with NO timeout\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        try:\n",
    "            # Remove all timeouts - unlimited processing time\n",
    "            timeout = aiohttp.ClientTimeout(total=None, connect=30)\n",
    "            async with session.post(\n",
    "                config.DOCUMENTS_URL, \n",
    "                data=form_data,\n",
    "                timeout=timeout\n",
    "            ) as response:\n",
    "                if response.status == 200:\n",
    "                    result = await response.json()\n",
    "                    job_id = result.get('job_id')\n",
    "                    print(f\"‚úÖ Upload initiated successfully!\")\n",
    "                    if job_id:\n",
    "                        print(f\"üìã Job ID: {job_id}\")\n",
    "                    \n",
    "                    # Start unlimited progress monitoring\n",
    "                    return await monitor_unlimited_progress(collection_name, initial_count, file_path)\n",
    "                else:\n",
    "                    text = await response.text()\n",
    "                    print(f\"‚ö†Ô∏è Upload failed with status: {response.status}\")\n",
    "                    print(f\"   Response: {text[:200]}...\")\n",
    "                    return False\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error uploading document: {e}\")\n",
    "            return False\n",
    "\n",
    "async def monitor_unlimited_progress(collection_name: str, initial_count: int, file_path: str) -> bool:\n",
    "    \"\"\"Monitor processing progress with UNLIMITED time - no timeouts\"\"\"\n",
    "    \n",
    "    print(f\"\\nüîÑ UNLIMITED PROGRESS MONITORING\")\n",
    "    print(f\"   Collection: {collection_name}\")\n",
    "    print(f\"   File: {os.path.basename(file_path)}\")\n",
    "    print(f\"   Initial documents: {initial_count}\")\n",
    "    print(f\"   ‚è∞ NO TIME LIMIT - will run until completion\")\n",
    "    print(f\"   ‚å®Ô∏è  Press Ctrl+C to interrupt if needed\\n\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    check_interval = 5  # Check every 5 seconds for better responsiveness\n",
    "    last_count = initial_count\n",
    "    \n",
    "    # Progress animation characters\n",
    "    progress_chars = ['‚†ã', '‚†ô', '‚†π', '‚†∏', '‚†º', '‚†¥', '‚†¶', '‚†ß']\n",
    "    progress_idx = 0\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            # Get current document count\n",
    "            current_count = await get_document_count(collection_name)\n",
    "            elapsed = time.time() - start_time\n",
    "            minutes = int(elapsed // 60)\n",
    "            seconds = int(elapsed % 60)\n",
    "            \n",
    "            # Animate progress indicator\n",
    "            progress_char = progress_chars[progress_idx % len(progress_chars)]\n",
    "            progress_idx += 1\n",
    "            \n",
    "            # Show progress line with better time display\n",
    "            status_msg = \"\"\n",
    "            if elapsed < 30:\n",
    "                status_msg = \"Starting processing...\"\n",
    "            elif elapsed < 60:\n",
    "                status_msg = \"Cloud API processing...\"\n",
    "            elif elapsed < 180:\n",
    "                status_msg = \"Still processing (normal for cloud APIs)...\"\n",
    "            else:\n",
    "                status_msg = f\"Long processing ({minutes}m {seconds}s) - cloud APIs can be slow...\"\n",
    "            \n",
    "            print(f\"\\r{progress_char} Time: {minutes:2d}m {seconds:2d}s | Docs: {current_count:2d} | {status_msg}\", end=\"\", flush=True)\n",
    "            \n",
    "            # Check if document count increased\n",
    "            if current_count > last_count:\n",
    "                print(f\"\\nüìà Document count increased! ({last_count} ‚Üí {current_count})\")\n",
    "                last_count = current_count\n",
    "                \n",
    "                # Check if processing completed\n",
    "                if current_count > initial_count:\n",
    "                    print(f\"\\n‚úÖ PROCESSING COMPLETED SUCCESSFULLY!\")\n",
    "                    print(f\"   üìä Final document count: {current_count}\")\n",
    "                    print(f\"   ‚è±Ô∏è  Total processing time: {minutes}m {seconds}s\")\n",
    "                    print(f\"   üéâ Document ready for RAG queries!\")\n",
    "                    return True\n",
    "            \n",
    "            # Wait before next check (shorter interval for better responsiveness)\n",
    "            await asyncio.sleep(check_interval)\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(f\"\\n‚ö†Ô∏è INTERRUPTED by user after {minutes}m {seconds}s\")\n",
    "        final_count = await get_document_count(collection_name)\n",
    "        success = final_count > initial_count\n",
    "        print(f\"   üìä Final document count: {final_count}\")\n",
    "        print(f\"   {'‚úÖ Processing succeeded' if success else '‚ùå Processing incomplete'}\")\n",
    "        return success\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERROR during progress monitoring: {e}\")\n",
    "        # Still check if processing succeeded\n",
    "        try:\n",
    "            final_count = await get_document_count(collection_name)\n",
    "            return final_count > initial_count\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "print(\"‚úÖ Unlimited time upload functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-upload-document",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üöÄ STARTING UNLIMITED TIME DOCUMENT UPLOAD\n",
      "================================================================================\n",
      "üìä Initial document count: 0\n",
      "üìÑ File: rag_test_document.md (2,977 bytes)\n",
      "üöÄ Starting upload with UNLIMITED processing time...\n",
      "   Will monitor progress until completion (no timeout)\n",
      "   Press Ctrl+C to interrupt if needed\n",
      "\n",
      "‚úÖ Upload initiated successfully!\n",
      "\n",
      "üîÑ UNLIMITED PROGRESS MONITORING\n",
      "   Collection: multimodal_data\n",
      "   File: rag_test_document.md\n",
      "   Initial documents: 0\n",
      "   ‚è∞ NO TIME LIMIT - will run until completion\n",
      "   ‚å®Ô∏è  Press Ctrl+C to interrupt if needed\n",
      "\n",
      "‚†ô Time:  0m 56s | Docs:  0 | Cloud API processing..."
     ]
    }
   ],
   "source": [
    "# === UPLOAD DOCUMENT WITH UNLIMITED TIME ===\n",
    "\n",
    "if health_status[\"overall_healthy\"] and collection_ready and test_file_path:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üöÄ STARTING UNLIMITED TIME DOCUMENT UPLOAD\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    upload_success = await upload_document_unlimited_time(test_file_path, config.COLLECTION_NAME)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    if upload_success:\n",
    "        print(\"üéâ UPLOAD AND PROCESSING COMPLETED SUCCESSFULLY!\")\n",
    "        print(\"   ‚úÖ Document is now in the knowledge base\")\n",
    "        print(\"   ‚úÖ Ready for RAG queries\")\n",
    "    else:\n",
    "        print(\"‚ùå UPLOAD/PROCESSING FAILED\")\n",
    "        print(\"   ‚ö†Ô∏è Document may not be available for queries\")\n",
    "        print(\"   üí° Check the progress output above for details\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è SKIPPING UPLOAD - Prerequisites not met\")\n",
    "    print(f\"   Health status: {health_status['overall_healthy']}\")\n",
    "    print(f\"   Collection ready: {collection_ready}\")\n",
    "    print(f\"   Test file ready: {test_file_path is not None}\")\n",
    "    upload_success = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-query-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === RAG QUERY FUNCTIONS ===\n",
    "\n",
    "def query_rag(question: str, collection_name: str = None) -> Optional[str]:\n",
    "    \"\"\"Send query to RAG service\"\"\"\n",
    "    if collection_name is None:\n",
    "        collection_name = config.COLLECTION_NAME\n",
    "    \n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": question\n",
    "            }\n",
    "        ],\n",
    "        \"use_knowledge_base\": True,\n",
    "        \"collection_names\": [collection_name],\n",
    "        \"stream\": False,\n",
    "        \"temperature\": 0.2,\n",
    "        \"top_p\": 0.7,\n",
    "        \"max_tokens\": 1024,\n",
    "        \"reranker_top_k\": 5,\n",
    "        \"vdb_top_k\": 20\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(config.CHAIN_URL, json=payload, headers=config.HEADERS, timeout=30)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            # Parse streaming response format\n",
    "            full_response = \"\"\n",
    "            \n",
    "            for line in response.text.split('\\n'):\n",
    "                if line.startswith('data: '):\n",
    "                    data_str = line[6:]  # Remove 'data: ' prefix\n",
    "                    if data_str and data_str != '[DONE]':\n",
    "                        try:\n",
    "                            data = json.loads(data_str)\n",
    "                            choices = data.get('choices', [])\n",
    "                            if choices:\n",
    "                                delta = choices[0].get('delta', {})\n",
    "                                content_chunk = delta.get('content', '')\n",
    "                                if content_chunk:\n",
    "                                    full_response += content_chunk\n",
    "                        except json.JSONDecodeError:\n",
    "                            continue\n",
    "            \n",
    "            return full_response if full_response else \"No response generated\"\n",
    "        else:\n",
    "            return f\"Query failed with status {response.status_code}: {response.text[:200]}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error querying RAG: {e}\"\n",
    "\n",
    "async def test_rag_queries() -> bool:\n",
    "    \"\"\"Test RAG system with comprehensive queries\"\"\"\n",
    "    \n",
    "    # First check document count\n",
    "    doc_count = await get_document_count(config.COLLECTION_NAME)\n",
    "    print(f\"üìä Current documents in knowledge base: {doc_count}\")\n",
    "    \n",
    "    if doc_count == 0:\n",
    "        print(\"‚ùå No documents in knowledge base!\")\n",
    "        print(\"   Queries will return generic responses\")\n",
    "        return False\n",
    "    \n",
    "    # Test queries that match our document content\n",
    "    test_queries = [\n",
    "        \"What is Python and when was it created?\",\n",
    "        \"What GPUs are mentioned in the document?\",\n",
    "        \"What is the capital of France?\",\n",
    "        \"Tell me about Docker containers\",\n",
    "        \"What does RAG stand for?\",\n",
    "        \"How many dimensions does the NVIDIA embedding model produce?\",\n",
    "        \"What is Milvus used for?\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nüß™ Testing {len(test_queries)} RAG queries...\\n\")\n",
    "    \n",
    "    successful_queries = 0\n",
    "    \n",
    "    for i, query in enumerate(test_queries, 1):\n",
    "        print(f\"üìù Query {i}/{len(test_queries)}: {query}\")\n",
    "        \n",
    "        response = query_rag(query)\n",
    "        \n",
    "        # Check if response contains actual information\n",
    "        if response and len(response.strip()) > 20:\n",
    "            # Check for generic \"couldn't find\" responses\n",
    "            if (\"couldn't find\" not in response.lower() and \n",
    "                \"more context\" not in response.lower() and\n",
    "                \"sorry\" not in response.lower()[:50] and\n",
    "                \"no information\" not in response.lower()):\n",
    "                successful_queries += 1\n",
    "                print(f\"üí¨ ‚úÖ Response: {response[:200]}{'...' if len(response) > 200 else ''}\")\n",
    "            else:\n",
    "                print(f\"üí¨ ‚ö†Ô∏è Generic response: {response[:150]}{'...' if len(response) > 150 else ''}\")\n",
    "        else:\n",
    "            print(f\"üí¨ ‚ùå No valid response\")\n",
    "        \n",
    "        print(\"-\" * 80)\n",
    "        time.sleep(1)  # Brief pause between queries\n",
    "    \n",
    "    # Summary\n",
    "    success_rate = (successful_queries / len(test_queries)) * 100\n",
    "    print(f\"\\nüìä RAG QUERY TEST RESULTS:\")\n",
    "    print(f\"   Successful queries: {successful_queries}/{len(test_queries)} ({success_rate:.1f}%)\")\n",
    "    print(f\"   Document count: {doc_count}\")\n",
    "    \n",
    "    if successful_queries > 0:\n",
    "        print(f\"   ‚úÖ RAG system is working correctly!\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"   ‚ùå RAG system may have issues\")\n",
    "        return False\n",
    "\n",
    "print(\"‚úÖ RAG query functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-test-queries",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TEST RAG QUERIES ===\n",
    "\n",
    "if health_status[\"overall_healthy\"] and upload_success:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üß™ TESTING RAG QUERY PIPELINE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    query_success = await test_rag_queries()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    if query_success:\n",
    "        print(\"üéâ RAG PIPELINE TEST COMPLETED SUCCESSFULLY!\")\n",
    "        print(\"   ‚úÖ Documents processed and stored correctly\")\n",
    "        print(\"   ‚úÖ Queries returning relevant information\")\n",
    "        print(\"   ‚úÖ RAG system fully operational\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è RAG PIPELINE TEST HAD ISSUES\")\n",
    "        print(\"   üîß May need troubleshooting\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è SKIPPING QUERY TESTS - Prerequisites not met\")\n",
    "    print(f\"   Services healthy: {health_status['overall_healthy']}\")\n",
    "    print(f\"   Upload successful: {upload_success}\")\n",
    "    query_success = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FINAL COMPREHENSIVE SUMMARY ===\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"üìã NVIDIA RAG BLUEPRINT - COMPLETE PIPELINE TEST SUMMARY\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "# Service Health\n",
    "print(f\"üè• Service Health: {'‚úÖ All Healthy' if health_status['overall_healthy'] else '‚ùå Issues Detected'}\")\n",
    "for service, status in health_status['services'].items():\n",
    "    emoji = \"‚úÖ\" if status.get('healthy') else \"‚ùå\"\n",
    "    print(f\"   {emoji} {service}\")\n",
    "\n",
    "# Collection Status\n",
    "print(f\"\\nüìÅ Collection Status: {'‚úÖ Ready' if collection_ready else '‚ùå Failed'}\")\n",
    "if collection_ready:\n",
    "    final_doc_count = await get_document_count(config.COLLECTION_NAME)\n",
    "    print(f\"   üìä Documents in '{config.COLLECTION_NAME}': {final_doc_count}\")\n",
    "\n",
    "# Upload Status\n",
    "print(f\"\\nüì§ Document Upload: {'‚úÖ Completed' if upload_success else '‚ùå Failed'}\")\n",
    "if upload_success:\n",
    "    print(f\"   ‚úÖ Processing completed with unlimited time\")\n",
    "    print(f\"   ‚úÖ Document ready for queries\")\n",
    "\n",
    "# Query Status  \n",
    "print(f\"\\nüß™ RAG Queries: {'‚úÖ Working' if query_success else '‚ùå Issues' if 'query_success' in locals() else '‚è≠Ô∏è Skipped'}\")\n",
    "if query_success:\n",
    "    print(f\"   ‚úÖ Knowledge base responding correctly\")\n",
    "    print(f\"   ‚úÖ RAG pipeline fully operational\")\n",
    "\n",
    "# Overall Status\n",
    "overall_success = health_status['overall_healthy'] and collection_ready and upload_success and query_success\n",
    "print(f\"\\nüéØ Overall Status: {'üéâ COMPLETE SUCCESS' if overall_success else '‚ö†Ô∏è PARTIAL SUCCESS / ISSUES'}\")\n",
    "\n",
    "if overall_success:\n",
    "    print(\"\\n‚ú® CONGRATULATIONS! ‚ú®\")\n",
    "    print(\"Your NVIDIA RAG Blueprint is fully operational:\")\n",
    "    print(\"   ‚Ä¢ All services running and healthy\")\n",
    "    print(\"   ‚Ä¢ Document processing with unlimited time works\")\n",
    "    print(\"   ‚Ä¢ Knowledge base populated and responding\")\n",
    "    print(\"   ‚Ä¢ Ready for production workloads\")\n",
    "else:\n",
    "    print(\"\\nüîß Next Steps:\")\n",
    "    if not health_status['overall_healthy']:\n",
    "        print(\"   1. Start all required services\")\n",
    "    if not collection_ready:\n",
    "        print(\"   2. Fix collection creation issues\")\n",
    "    if not upload_success:\n",
    "        print(\"   3. Troubleshoot document processing (check cloud API keys)\")\n",
    "    if not query_success:\n",
    "        print(\"   4. Debug RAG query pipeline\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"üìù KEY FEATURES IMPLEMENTED:\")\n",
    "print(\"   ‚úÖ Unlimited processing time (no timeouts)\")\n",
    "print(\"   ‚úÖ Real-time progress monitoring with animations\")\n",
    "print(\"   ‚úÖ Proper error handling and recovery\")\n",
    "print(\"   ‚úÖ Complete end-to-end pipeline testing\")\n",
    "print(\"   ‚úÖ Comprehensive health checking\")\n",
    "print(\"   ‚úÖ Single test document creation (no duplicates)\")\n",
    "print(\"=\"*90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CLEANUP (OPTIONAL) ===\n",
    "\n",
    "# Uncomment the next lines if you want to clean up the test document\n",
    "# if test_file_path and os.path.exists(test_file_path):\n",
    "#     os.remove(test_file_path)\n",
    "#     print(f\"‚úÖ Cleaned up test file: {test_file_path}\")\n",
    "\n",
    "print(\"‚úÖ Notebook execution complete\")\n",
    "if test_file_path:\n",
    "    print(f\"   Test document preserved: {test_file_path}\")\n",
    "print(\"   All functions remain available for further testing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
