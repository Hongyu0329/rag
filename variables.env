#-------------------------------------------------------------------------------
# Core Application Configuration
#-------------------------------------------------------------------------------
# Log level for the application
RAG_LOG_LEVEL=INFO

#-------------------------------------------------------------------------------
# LLM and Embedding Model Configuration
#
# We are configuring this to use a local, GGUF-quantized model to fit
# within the VRAM of your RTX 5070 Ti. We will use a Llama-3 based model,
# which offers excellent performance.
#-------------------------------------------------------------------------------
# The LLM to use for generating answers.
# We are using a quantized Llama-3 model which is a good fit for your GPU.
# You will need to download this model separately.
LLM_MODEL_NAME="llama3"
LLM_MODEL_PATH="/path/to/your/models/Meta-Llama-3-8B-Instruct.Q4_K_M.gguf"

# The embedding model for vectorizing your documents.
# This will be downloaded automatically.
EMBEDDING_MODEL_NAME="BAAI/bge-large-en-v1.5"

# The reranker model to improve search results.
# This will be downloaded automatically.
RERANKER_MODEL_NAME="BAAI/bge-reranker-base"

#-------------------------------------------------------------------------------
# Vector Store Configuration
#
# We will use Milvus, a popular open-source vector database, which will be
# run in a Docker container as part of the docker-compose setup.
#-------------------------------------------------------------------------------
VECTOR_STORE_TYPE="milvus"
VECTOR_STORE_HOST="milvus"
VECTOR_STORE_PORT="19530"

#-------------------------------------------------------------------------------
# Ingestor and API Server Configuration
#-------------------------------------------------------------------------------
INGESTOR_API_HOST="0.0.0.0"
INGESTOR_API_PORT="8000"

RAG_API_HOST="0.0.0.0"
RAG_API_PORT="8888"

#-------------------------------------------------------------------------------
# NVIDIA API Keys (Optional)
#
# If you want to use NVIDIA's hosted models instead of local ones,
# you will need to provide your API keys here. For a fully local setup,
# these can be left blank.
#-------------------------------------------------------------------------------
# NVIDIA_API_KEY=""
NGC_API_KEY="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"